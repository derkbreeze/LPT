{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving a constrained Integer Linear Program using learned cost\n",
    "\n",
    "We consider the problem of minimizing a constrained ILP program. The problem can be written formally as\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathbf{x}^{\\ast} =& \\mathop{\\arg\\min}_{\\mathbf{x} \\in \\mathcal{X}} \\mathbf{c(f;\\mathbf{w})}^T \\mathbf{x} \\\\\n",
    "&\\text{s.t.} \\begin{aligned}[t]\n",
    "     \\mathbf{A}\\mathbf{x} & = \\mathbf{b} \\\\\n",
    "     \\mathbf{G}\\mathbf{x} & \\leq \\mathbf{h}\n",
    "  \\end{aligned}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where $\\mathbf{c(f;\\mathbf{w})} \\in \\mathbb{R}^n$ is the cost function parametrized by $\\mathbf{\\mathbf{w}}$, given input $\\mathbf{f}$. And $\\mathbf{A,b}$ and $\\mathbf{G,h}$ defines the equality and in-equality constraints, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, time\n",
    "import cv2, random\n",
    "import pickle, joblib\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import gurobipy as gp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from lib.tracking import Tracker\n",
    "from lib.utils import getIoU, computeBoxFeatures, interpolateTrack, interpolateTracks\n",
    "\n",
    "class Net(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(6,6), nn.ReLU(), nn.Linear(6,1))\n",
    "    def forward(self, data):\n",
    "        x = self.fc(data.edge_attr)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('ckpt/qp/epoch_8.pth'))\n",
    "#net.load_state_dict(torch.load('ckpt/qp/epoch_11.pth'))\n",
    "\n",
    "#net.load_state_dict(torch.load('../ckpt/bce/epoch_0010.pth'))\n",
    "#net.load_state_dict(torch.load('../ckpt/spo_mlp/epoch_15.pth'))\n",
    "#net.load_state_dict(torch.load('../ckpt/qptl_l2/epoch_0009.pth'))\n",
    "#net.load_state_dict(torch.load('../ckpt/qptl_l1/epoch_0009.pth'))\n",
    "\n",
    "tracker = Tracker(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans_probs(tracker, curr_dets, curr_app_feats, app_thresh, max_frame_gap = 5):\n",
    "    \"\"\"\n",
    "    Inputs: tracker: an instance of the Tracker.\n",
    "            curr_dets: frame, x1, y1, x2, y2, det_confidence, node_ind.\n",
    "            curr_app_feats: normalized appearance features for curr_dets.\n",
    "            max_frame_gap: frame gap used to connect detections.\n",
    "    Return: transition probabilities for LP that handles false negatives(missing detections).\n",
    "    \"\"\"\n",
    "    edge_ind = 0\n",
    "    edge_feats, lifted_probs = [], []\n",
    "    edge_type = [] #1:base edge 2:lifted edge-1:pruned lifted edge\n",
    "    \n",
    "    cos_sim_mat = np.dot(curr_app_feats, curr_app_feats.T)\n",
    "    linkIndexGraph = np.zeros((curr_dets.shape[0], curr_dets.shape[0]), dtype=np.int32)\n",
    "    for i in range(curr_dets.shape[0]):\n",
    "        for j in range(curr_dets.shape[0]):\n",
    "            frame_gap = curr_dets[j][0] - curr_dets[i][0]\n",
    "            cos_sim = cos_sim_mat[i, j]\n",
    "\n",
    "            if frame_gap == 1: #base edge\n",
    "                edge_type.append(1)\n",
    "                feats = computeBoxFeatures(curr_dets[i, 1:5], curr_dets[j, 1:5])\n",
    "                iou = getIoU(curr_dets[i, 1:5], curr_dets[j, 1:5])\n",
    "                feats.extend((iou, cos_sim))\n",
    "                edge_feats.append(feats)\n",
    "                edge_ind += 1\n",
    "                linkIndexGraph[i, j] = edge_ind\n",
    "\n",
    "            elif frame_gap > 1 and frame_gap <= max_frame_gap: #lifted edge\n",
    "                if cos_sim > app_thresh:\n",
    "                    edge_type.append(2)\n",
    "                    time_weight = 0.9 ** frame_gap\n",
    "                    lifted_probs.append(cos_sim * time_weight)\n",
    "                else:\n",
    "                    edge_type.append(-1)\n",
    "\n",
    "                edge_ind += 1\n",
    "                linkIndexGraph[i, j] = edge_ind\n",
    "                \n",
    "    edge_type = np.array(edge_type)\n",
    "    edge_feats = torch.Tensor(edge_feats)\n",
    "    with torch.no_grad():\n",
    "        prob = tracker.net.fc(edge_feats)\n",
    "        prob = torch.clamp(prob, min=1e-7, max=1-1e-7).flatten().numpy()\n",
    "\n",
    "    probs = np.zeros(edge_ind)\n",
    "    base_inds = np.where(edge_type == 1)[0]\n",
    "    lifted_inds = np.where(edge_type == 2)[0]\n",
    "    pruned_lifted_inds = np.where(edge_type == -1)[0]\n",
    "    probs[base_inds] = prob            #base probs\n",
    "    probs[lifted_inds] = lifted_probs  #lifted probs\n",
    "    return linkIndexGraph, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence MOT17-01, DPM detection, app thresh 0.75, dist thresh 100, retain length 3\n",
      "Tracking from frame 1 to 100\n",
      "0-th iteration\n",
      "Academic license - for non-commercial use only - expires 2025-03-17\n",
      "Using license file /home/lishuai/gurobi.lic\n",
      "1-th iteration\n",
      "Tracking from frame 96 to 195\n",
      "0-th iteration\n",
      "1-th iteration\n",
      "Tracking from frame 191 to 290\n",
      "0-th iteration\n",
      "1-th iteration\n",
      "Tracking from frame 286 to 385\n",
      "0-th iteration\n",
      "1-th iteration\n",
      "Tracking from frame 381 to 450\n",
      "0-th iteration\n",
      "1-th iteration\n",
      "Finished tracking, saving to ./MOT17-01-DPM.txt\n"
     ]
    }
   ],
   "source": [
    "app_thresh = 0.75 #0.7, 0.8\n",
    "nms_thresh, eps = 0.3, 1e-7\n",
    "\n",
    "#for sequence in ['MOT17-01', 'MOT17-03', 'MOT17-06', 'MOT17-07', 'MOT17-08', 'MOT17-12', 'MOT17-14']:\n",
    "for seq in ['MOT17-01']:\n",
    "    \n",
    "    #Static camera, moving camera\n",
    "    if seq in ['MOT17-03']:\n",
    "        batch_size, dist_thresh, prune_len = 50, 50, 2 #tracklets less than 2 are pruned\n",
    "    else:\n",
    "        batch_size, dist_thresh, prune_len = 100, 100, 3\n",
    "        \n",
    "    if seq == 'MOT17-06':\n",
    "        img_Height, img_Width = 480, 640\n",
    "    else:\n",
    "        img_Height, img_Width = 1080, 1920\n",
    "        \n",
    "    #for detector in ['DPM','FRCNN','SDP']:\n",
    "    for detector in ['DPM']:\n",
    "        print('Sequence {}, {} detection, app thresh {}, dist thresh {}, retain length {}'.format(\n",
    "            seq, detector, app_thresh, dist_thresh, prune_len))\n",
    "        \n",
    "        det_file = './data/{}/det_{}.txt'.format(seq, detector)\n",
    "        app_file = './data/{}/app_det_{}.npy'.format(seq, detector)\n",
    "        dets = np.loadtxt(det_file, delimiter=',')\n",
    "        app_feats = np.load(app_file)\n",
    "        assert dets.shape[0] == app_feats.shape[0], 'Shape mismatch'\n",
    "\n",
    "        batch_overlap = 5                  #Number of frames to overlap between 2 batches\n",
    "        num_frames = int(dets[:, 0].max()) #Number of frames for this video\n",
    "        tracks_list, assignments_list, features_list, nms_list = [],[],[],[]\n",
    "        \n",
    "        for start_frame in range(1, num_frames+1, batch_size-batch_overlap):\n",
    "            end_frame = start_frame + batch_size - 1\n",
    "            if end_frame >= num_frames:\n",
    "                end_frame = num_frames\n",
    "                \n",
    "            print('Tracking from frame %d to %d'%(start_frame, end_frame))\n",
    "            curr_ind = np.logical_and(dets[:, 0] >= start_frame, dets[:, 0] <= end_frame)\n",
    "            curr_dets = np.concatenate([dets[curr_ind, 0][:, None], dets[curr_ind, 2:7],\n",
    "                                        np.arange(dets[curr_ind].shape[0])[:, None]], axis=1)\n",
    "\n",
    "            curr_dets[:, 3:5] = curr_dets[:, 3:5] + curr_dets[:, 1:3] # convert to frame,x1,y1,x2,y2,conf,node_ind\n",
    "            curr_app_feats = app_feats[curr_ind]\n",
    "            curr_app_feats = curr_app_feats / np.linalg.norm(curr_app_feats, axis=1, keepdims=True)\n",
    "            for iteration in range(2):\n",
    "                if iteration == 0:\n",
    "                    print('%d-th iteration'%iteration)\n",
    "                    linkIndexGraph, probs = get_trans_probs(tracker, curr_dets, curr_app_feats, \n",
    "                                                            app_thresh, max_frame_gap = 5)\n",
    "                    \n",
    "                    trans_cost = - np.log(probs+eps) #np.log((1-probs+eps)/(probs+eps))\n",
    "                    det_cost = -curr_dets[:, -2]\n",
    "                    entry_cost = 0.5 * np.ones(det_cost.shape[0])\n",
    "                    exit_cost = entry_cost\n",
    "                    cost = np.concatenate((det_cost, entry_cost, exit_cost, trans_cost))\n",
    "\n",
    "                    A_eq, b_eq, A_ub, b_ub = tracker.build_constraint(linkIndexGraph)\n",
    "                    sol = tracker.linprog(c=cost, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub)\n",
    "                    \n",
    "                    tracklets = tracker.recoverTracklets(curr_dets, sol, linkIndexGraph, prune_len=prune_len)    \n",
    "                    tracklets_ = np.delete(tracklets, -1, axis=1)\n",
    "                    interpolated_tracklets = interpolateTracks(tracklets_)\n",
    "                    \n",
    "                else:\n",
    "                    print('%d-th iteration'%iteration)\n",
    "                    assignment_list, feature_list = tracker.clusterSkipTracklets(tracklets, curr_app_feats, \n",
    "                                                                                 dist_thresh, app_thresh)\n",
    "                    tracks = tracker.recoverClusteredTracklets(tracklets, assignment_list)\n",
    "                    tracks = interpolateTracks(tracks)\n",
    "\n",
    "                    assignments_list.append(assignment_list)\n",
    "                    feature_array = np.stack(feature_list)\n",
    "                    feature_array = feature_array / np.linalg.norm(feature_array, axis=1, keepdims=True)\n",
    "            #break\n",
    "            tracks_list.append(tracks)\n",
    "            features_list.append(feature_array)\n",
    "            \n",
    "        final_tracks = tracker.stitchTracklets(tracks_list, features_list)\n",
    "        save_file = './MOT17-{}-{}.txt'.format(seq.split('-')[1], detector)\n",
    "        print('Finished tracking, saving to {}'.format(save_file))\n",
    "        np.savetxt(save_file, final_tracks, fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show final tracking and detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save dir BYTE_Results/MOT17-01-DPM\n",
      "Processing frame 100\n",
      "Processing frame 200\n",
      "Processing frame 300\n",
      "Processing frame 400\n",
      "save dir BYTE_Results/MOT17-03-DPM\n",
      "Processing frame 100\n",
      "Processing frame 200\n",
      "Processing frame 300\n",
      "Processing frame 400\n",
      "save dir BYTE_Results/MOT17-06-DPM\n",
      "Processing frame 100\n",
      "Processing frame 200\n",
      "Processing frame 300\n",
      "Processing frame 400\n",
      "save dir BYTE_Results/MOT17-07-DPM\n",
      "Processing frame 100\n",
      "Processing frame 200\n",
      "Processing frame 300\n",
      "Processing frame 400\n",
      "save dir BYTE_Results/MOT17-08-DPM\n",
      "Processing frame 100\n",
      "Processing frame 200\n",
      "Processing frame 300\n",
      "Processing frame 400\n",
      "save dir BYTE_Results/MOT17-12-DPM\n",
      "Processing frame 100\n",
      "Processing frame 200\n",
      "Processing frame 300\n",
      "Processing frame 400\n",
      "save dir BYTE_Results/MOT17-14-DPM\n",
      "Processing frame 100\n",
      "Processing frame 200\n",
      "Processing frame 300\n",
      "Processing frame 400\n"
     ]
    }
   ],
   "source": [
    "#seq = 'MOT17-03'\n",
    "detector = 'DPM'\n",
    "\n",
    "for seq in ['MOT17-01', 'MOT17-03', 'MOT17-06', 'MOT17-07', 'MOT17-08', 'MOT17-12', 'MOT17-14']:\n",
    "    \n",
    "    save_dir = 'BYTE_Results/{}-{}'.format(seq, detector)\n",
    "    print('save dir {}'.format(save_dir))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    #tracks: frame, ID, x, y, w, h, -1, -1, -1, -1\n",
    "    #dets:   frame, -1, x, y, w, h, conf, -1, -1, -1\n",
    "    tracks = np.loadtxt('BYTE_Results/MOT17-01-DPM.txt', delimiter=',')\n",
    "    tracks = tracks.astype(np.int)\n",
    "    \n",
    "    colors = np.random.rand(1000,3)\n",
    "    resize_scale = 0.5\n",
    "    for frame in range(tracks[:, 0].min(), tracks[:, 0].max()+1):\n",
    "        if frame % 100 == 0:\n",
    "            print('Processing frame {}'.format(frame))\n",
    "        \n",
    "        img_file = os.path.join('/home/lishuai/Experiment/MOT/MOT17/test/{}-{}/img1/{:06d}.jpg'.format(seq,detector,frame))\n",
    "        img = cv2.imread(img_file)\n",
    "        img = cv2.resize(img, (int(resize_scale*img.shape[1]), int(resize_scale*img.shape[0])))\n",
    "        cv2.putText(img, '{:04}'.format(frame), (0,50) ,cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,0,255), thickness=2)\n",
    "        bboxes = tracks[tracks[:, 0] == frame, 1:6]\n",
    "        \n",
    "        if bboxes.shape[0] != 0:\n",
    "            #detections = dets[dets[:, 0] == frame, 2:7]\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                ID = int(bboxes[i][0])\n",
    "                x, y = int(resize_scale*(bboxes[i][1])), int(resize_scale*(bboxes[i][2]))\n",
    "                w, h = int(resize_scale*(bboxes[i][3])), int(resize_scale*(bboxes[i][4]))\n",
    "                cv2.rectangle(img, (x,y),(x+w,y+h), 255*colors[ID], thickness=2)\n",
    "                cv2.putText(img, str(ID), (x,y) ,cv2.FONT_HERSHEY_SIMPLEX, 0.8, 255*colors[ID], thickness=2)\n",
    "\n",
    "    #         for i in range(detections.shape[0]):\n",
    "    #             x, y = int(resize_scale*(detections[i][0])), int(resize_scale*(detections[i][1]))\n",
    "    #             w, h = int(resize_scale*(detections[i][2])), int(resize_scale*(detections[i][3]))\n",
    "    #             score = detections[i][4] \n",
    "    #             drawrect(img,(x,y),(x+w,y+h),(0,0,255),2,'dotted')\n",
    "        cv2.imwrite(save_dir+'/'+'{:06d}.jpg'.format(frame), img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
