{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving a constrained Integer Linear Program using learned cost\n",
    "\n",
    "We consider the problem of minimizing a constrained ILP program. The problem can be written formally as\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathbf{x}^{\\ast} =& \\mathop{\\arg\\min}_{\\mathbf{x} \\in \\mathcal{X}} \\mathbf{c(f;\\mathbf{w})}^T \\mathbf{x} \\\\\n",
    "&\\text{s.t.} \\begin{aligned}[t]\n",
    "     \\mathbf{A}\\mathbf{x} & = \\mathbf{b} \\\\\n",
    "     \\mathbf{G}\\mathbf{x} & \\leq \\mathbf{h}\n",
    "  \\end{aligned}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where $\\mathbf{c(f;\\mathbf{w})} \\in \\mathbb{R}^n$ is the cost function parametrized by $\\mathbf{\\mathbf{w}}$, given input $\\mathbf{f}$. And $\\mathbf{A,b}$ and $\\mathbf{G,h}$ defines the equality and in-equality constraints, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lishuai/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import sklearn, pickle, random, time, datetime, cv2, os, joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import gurobipy as gp\n",
    "from lib.utils import getIoU,computeBoxFeatures, pruneTracks\n",
    "from lib.inference import forwardLP, generateGraph, buildConstraint, buildConstraintTracklet, clusterTracklets\n",
    "from lib.postprocess import recoverTracklets, recoverClusteredTracklets, mergeTracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(6,6), nn.ReLU(), nn.Linear(6,1))\n",
    "    def forward(self, data):\n",
    "        x = self.fc(data)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n",
    "net = Model()\n",
    "net.load_state_dict(torch.load('ckpt/qp/epoch_8.pth'))\n",
    "#net.load_state_dict(torch.load('ckpt/qp/epoch_11.pth'))\n",
    "\n",
    "def getTransitionCost(net, curr_dets, curr_app_feat_norm, maxFrameGap = 1):\n",
    "    \"\"\"\n",
    "    Get the transition cost of network flow, entry/exit and detection costs should be included later as a whole.\n",
    "    net: an instance of the matching network, MLP.\n",
    "    curr_dets: np.ndarray, frame, x1, y1, x2, y2, conf, node_ind \n",
    "    curr_app_feat_norm: Nxd array, normalized appearance features for curr_det, N the number of detections.\n",
    "    maxFrameGap: frame gap used to connect detections.\n",
    "    \"\"\"\n",
    "    edge_feat_list = []\n",
    "    iou_list = []\n",
    "    for i in range(curr_dets.shape[0]):\n",
    "        for j in range(curr_dets.shape[0]):\n",
    "            frameGap = curr_dets[j][0] - curr_dets[i][0]\n",
    "            if frameGap == maxFrameGap:\n",
    "                box_feats = computeBoxFeatures(curr_dets[i, 1:5], curr_dets[j, 1:5])\n",
    "                iou = getIoU(curr_dets[i, 1:5], curr_dets[j, 1:5])\n",
    "                rel_app = np.dot(curr_app_feat_norm[i], curr_app_feat_norm[j])\n",
    "                box_feats.extend((iou, rel_app))\n",
    "                edge_feat_list.append(box_feats)\n",
    "    edge_feats = np.array(edge_feat_list)\n",
    "    prob = net(torch.from_numpy(edge_feats).float())\n",
    "    prob = torch.clamp(prob, min=1e-7, max=1-1e-7)\n",
    "    prob = prob.detach().numpy() \n",
    "    edgeCost = - np.log(prob + 1e-05) \n",
    "    #edgeCost = np.log((1-prob+1e-05)/(prob+1e-05))\n",
    "    return edgeCost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_thres, dist_thres, nms_thre = 0.75, 100, 0.3\n",
    "prune_len = 3\n",
    "\n",
    "for sequence in ['MOT17-01', 'MOT17-03', 'MOT17-06', 'MOT17-07', 'MOT17-08', 'MOT17-12', 'MOT17-14']:\n",
    "    for detector in ['DPM', 'FRCNN', 'SDP']:\n",
    "        \n",
    "        if sequence == 'MOT17-03':\n",
    "            batch_size = 70 #MOT17-03 is rather crowd, it is more efficient to work on small batch size\n",
    "        else:\n",
    "            batch_size = 100\n",
    "\n",
    "        batch_overlap = 5  #temporal overlapping frames between two batches\n",
    "        tracks_list, assignments_list, features_list, nms_list = [],[],[],[]\n",
    "\n",
    "        #det_file = '/home/lishuai/Experiment/MOT/MOT17/ByteTrack/dets/{}-{}.txt'.format(sequence, detector)\n",
    "        #app_file = '/home/lishuai/Experiment/MOT/MOT17/ByteTrack/app/{}-{}.npy'.format(sequence, detector)\n",
    "\n",
    "        det_file = '/home/lishuai/Experiment/MOT/LP/data/{}/det_{}.txt'.format(sequence, detector)\n",
    "        app_file = '/home/lishuai/Experiment/MOT/LP/data/{}/app_det_{}.npy'.format(sequence, detector)\n",
    "\n",
    "        print('On {} and {}'.format(sequence, detector))\n",
    "        dets = np.loadtxt(det_file, delimiter=',')\n",
    "#         if np.unique(dets[:, 6]).shape[0] == 1:\n",
    "#             print('No detector confidence used, assuming they are all one')\n",
    "#             dets[:, 6] = np.ones_like(dets[:, 6])\n",
    "\n",
    "        app_feat = np.load(app_file)\n",
    "        assert dets.shape[0] == app_feat.shape[0], 'Shape Mismatch!'\n",
    "        num_frames = int(dets[:, 0].max()) # number of frames in this sequence\n",
    "        for start_frame in range(1, num_frames+1, batch_size-batch_overlap):\n",
    "            end_frame = start_frame + batch_size - 1\n",
    "            if end_frame >= num_frames:\n",
    "                end_frame = num_frames\n",
    "            print('Tracking from frame %d to %d'%(start_frame, end_frame))\n",
    "            start_time = time.time()\n",
    "\n",
    "            curr_ind = np.logical_and(dets[:, 0] >= start_frame, dets[:, 0] <= end_frame)\n",
    "            curr_dets = np.concatenate([dets[curr_ind, 0][:, None], \n",
    "                                        dets[curr_ind, 2:7],\n",
    "                                        np.arange(dets[curr_ind].shape[0])[:, None]],\n",
    "                                        axis=1)\n",
    "\n",
    "            curr_dets[:, 3:5] = curr_dets[:, 3:5] + curr_dets[:, 1:3] # convert to frame,x1,y1,x2,y2,conf,det_index\n",
    "            curr_app_feat = app_feat[curr_ind]\n",
    "            curr_app_feat_norm = curr_app_feat / np.linalg.norm(curr_app_feat, axis=1, keepdims=True)\n",
    "            for iteration in range(2):\n",
    "                if iteration == 0:\n",
    "                    print('%d-th iteration'%iteration)\n",
    "                    detCost = -1 * curr_dets[:, -2][:, None]\n",
    "                    entryCost = 0.5 * np.ones((curr_dets.shape[0], 1))\n",
    "                    exitCost = 0.5 * np.ones((curr_dets.shape[0], 1))\n",
    "                    transitionCost = getTransitionCost(net, curr_dets, curr_app_feat_norm, 1)\n",
    "                    cost = np.concatenate([detCost, entryCost, exitCost, transitionCost], axis=0).squeeze()\n",
    "                    linkIndexGraph = generateGraph(curr_dets)\n",
    "                    A_eq, b_eq, A_ub, b_ub = buildConstraint(linkIndexGraph)\n",
    "                    sol = forwardLP(c=cost, A_eq=A_eq, b_eq=b_eq, A_ub=A_ub, b_ub=b_ub)\n",
    "                    tracklets = recoverTracklets(curr_dets, sol, linkIndexGraph, prune_len=prune_len) \n",
    "                else:\n",
    "                    print('%d-th iteration'%iteration)\n",
    "                    assignment_list, feature_list = clusterTracklets(tracklets, curr_app_feat_norm, dist_thres, app_thres)\n",
    "                    tracks = recoverClusteredTracklets(tracklets, assignment_list)\n",
    "                    #Do some batch-level post processing steps here.\n",
    "                    assignments_list.append(assignment_list)\n",
    "                    tracks, nms_array = pruneTracks(tracks, nms_thresh)\n",
    "                    tracks = tracks.astype(np.int32)\n",
    "                    nms_list.append(nms_array)\n",
    "                    #import ipdb; ipdb.set_trace()\n",
    "                    feature_array = np.array(feature_list)[(1-nms_array).astype(np.bool)]\n",
    "                    feature_array = feature_array/np.linalg.norm(feature_array, axis=1, keepdims=True)\n",
    "            tracks_list.append(tracks)\n",
    "            features_list.append(feature_array)\n",
    "\n",
    "            end_time = time.time()\n",
    "            print('Elapsed time is {:.2f} seconds'.format(end_time - start_time))\n",
    "            del A_eq, b_eq, A_ub, b_ub\n",
    "\n",
    "        tracks = mergeTracklets(tracks_list, features_list)\n",
    "        #save_file = 'BYTE_Results/{}.txt'.format(sequence)\n",
    "        save_file = '{}.txt'.format(sequence) \n",
    "        print('Finished tracking, saving to {}'.format(save_file))\n",
    "        np.savetxt(save_file, tracks, fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = np.random.rand(5000, 3)\n",
    "# resize_scale = 0.5\n",
    "# for frame in range(tracks[:, 0].min(), tracks[:, 0].max()+1):\n",
    "#     if frame % 100 == 0:\n",
    "#         print('Writing to frame %d' %frame)\n",
    "#     img_file = os.path.join('/home/lishuai/Experiment/MOT/MOT20/test/{}/img1/{:06d}.jpg'.format(sequence, frame))\n",
    "#     img = cv2.imread(img_file)\n",
    "#     img = cv2.resize(img, (int(resize_scale*img.shape[1]), int(resize_scale*img.shape[0])))\n",
    "#     cv2.putText(img, '{:04}'.format(frame), (0,50) ,cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,0,255), thickness=2)\n",
    "    \n",
    "#     bboxes = tracks[tracks[:, 0] == frame, 0:6]    \n",
    "#     if bboxes.shape[0] == 0:\n",
    "#         pass\n",
    "#     else:\n",
    "#         for i in range(bboxes.shape[0]):            \n",
    "#             ID = int(bboxes[i][1])\n",
    "#             x, y = int(resize_scale*(bboxes[i][2])), int(resize_scale*(bboxes[i][3]))\n",
    "#             w, h = int(resize_scale*(bboxes[i][4])) , int(resize_scale*(bboxes[i][5])) \n",
    "#             cv2.rectangle(img, (x,y),(x+w,y+h), 255*colors[ID], thickness=2)\n",
    "#             cv2.putText(img, str(ID), (x,y) ,cv2.FONT_HERSHEY_SIMPLEX, 0.8, 255*colors[ID], thickness=2)\n",
    "            \n",
    "#     cv2.imwrite('MOT20-04/tracks/{:06d}.jpg'.format(frame), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visDetections(sequence, detector, detections, save_dir):\n",
    "    \n",
    "#     resize_scale = 0.5\n",
    "#     for frame in range(int(dets[:, 0].min()), int(dets[:, 0].max())+1):\n",
    "#         img_file = os.path.join('/home/lishuai/Experiment/MOT/MOT17/test/MOT17-{}-{}/img1/{:06d}.jpg'.format(\n",
    "#             sequence.split('-')[1], detector, frame))\n",
    "#         img = cv2.imread(img_file)\n",
    "#         img = cv2.resize(img, (int(resize_scale*img.shape[1]), int(resize_scale*img.shape[0])))\n",
    "#         cv2.putText(img, '{:04}'.format(frame), (0,50) ,cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,0,255), thickness=2)\n",
    "#         bboxes = detections[detections[:, 0] == frame, 2:7]\n",
    "\n",
    "#         for i in range(bboxes.shape[0]):\n",
    "#             x  = int(resize_scale*(bboxes[i][0]))\n",
    "#             y  = int(resize_scale*(bboxes[i][1]))\n",
    "#             w  = int(resize_scale*(bboxes[i][2])) \n",
    "#             h  = int(resize_scale*(bboxes[i][3])) \n",
    "#             score = bboxes[i][4]\n",
    "\n",
    "#             drawrect(img,(x,y),(x+w,y+h),(0,0,255),2,'dotted')\n",
    "#             cv2.putText(img, '{:.2f}'.format(score), (x,y-5) ,cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "#         cv2.imwrite(save_dir + '/' + '{:06d}.jpg'.format(frame), img)\n",
    "\n",
    "# print(sequence, detector)\n",
    "# visDetections(sequence, detector, dets, save_dir='tmp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
